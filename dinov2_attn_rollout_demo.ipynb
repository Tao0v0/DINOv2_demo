{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# DINOv2 Attention Rollout Demo\n",
    "\n",
    "本 Notebook 展示如何：\n",
    "1) 加载预训练的 DINOv2 ViT 并提取图像特征；\n",
    "2) 使用 **Attention Rollout** 可视化注意力图。\n",
    "\n",
    "> 模型：Hugging Face `facebook/dinov2-small`（支持 CPU/GPU）\n",
    "\n",
    "👉 你可以：\n",
    "- 直接跑我们提供的示例图片；\n",
    "- 或者上传你自己的机器人采集图像进行可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": [
    "!pip -q install --upgrade torch torchvision transformers pillow matplotlib opencv-python\n",
    "import torch, torchvision\n",
    "from transformers import AutoImageProcessor, Dinov2Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests, io, cv2\n",
    "from typing import List\n",
    "print('Torch:', torch.__version__, '| CUDA available:', torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_model"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = 'facebook/dinov2-small'  # 约22M参数，课堂演示足够\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL_ID)\n",
    "model = Dinov2Model.from_pretrained(MODEL_ID, output_attentions=True).to(device).eval()\n",
    "print('Loaded', MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utils"
   },
   "outputs": [],
   "source": [
    "def load_image_from_url(url: str, size: int = 518) -> Image.Image:\n",
    "    # DINOv2 建议输入尺寸能被 patch_size 整除（small 模型 patch=14），518 在示例中常用\n",
    "    img = Image.open(io.BytesIO(requests.get(url, timeout=10).content)).convert('RGB')\n",
    "    img = img.resize((size, size))\n",
    "    return img\n",
    "\n",
    "def preprocess(img: Image.Image):\n",
    "    inputs = processor(images=img, return_tensors='pt')\n",
    "    return {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "def attention_rollout(attentions: List[torch.Tensor], head_fusion: str = 'mean', start_layer: int = 0):\n",
    "    \"\"\"\n",
    "    attentions: list of (B, num_heads, T, T)\n",
    "    返回 (B, T) CLS->token 的注意力得分（已rollout）\n",
    "    参考：Abnar & Zuidema, 2020；ViT 论文附录做法\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # 选层范围\n",
    "        attns = attentions[start_layer:]\n",
    "        # 融合 head（mean/max/min）\n",
    "        if head_fusion == 'mean':\n",
    "            attns = [a.mean(dim=1) for a in attns]  # (B, T, T)\n",
    "        elif head_fusion == 'max':\n",
    "            attns = [a.max(dim=1).values for a in attns]\n",
    "        elif head_fusion == 'min':\n",
    "            attns = [a.min(dim=1).values for a in attns]\n",
    "        else:\n",
    "            raise ValueError('head_fusion must be one of [mean, max, min]')\n",
    "\n",
    "        # 加 I 并重新归一化（考虑残差对信息流的影响）\n",
    "        attns = [a + torch.eye(a.size(-1), device=a.device).unsqueeze(0) for a in attns]\n",
    "        attns = [a / a.sum(dim=-1, keepdim=True) for a in attns]\n",
    "\n",
    "        # 逐层相乘\n",
    "        rollout = attns[0]\n",
    "        for a in attns[1:]:\n",
    "            rollout = torch.bmm(a, rollout)\n",
    "\n",
    "        # 取 CLS token 对所有 token 的注意力（CLS 在索引0）\n",
    "        cls_attn = rollout[:, 0]  # (B, T)\n",
    "        return cls_attn\n",
    "\n",
    "def show_attention_on_image(img: Image.Image, attn_map_2d: np.ndarray, alpha: float = 0.5):\n",
    "    # 将注意力图 resize 到原图大小，并叠加可视化\n",
    "    h, w = img.size[1], img.size[0]\n",
    "    attn = cv2.resize(attn_map_2d, (w, h))\n",
    "    attn = (attn - attn.min()) / (attn.max() - attn.min() + 1e-8)\n",
    "    heat = (plt.cm.jet(attn)[..., :3] * 255).astype(np.uint8)\n",
    "    over = cv2.addWeighted(np.array(img), 1 - alpha, heat, alpha, 0)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(over)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "demo_images"
   },
   "outputs": [],
   "source": [
    "# 示例图片（你可替换为机器人拍摄图像的 URL）\n",
    "IMAGE_URLS = [\n",
    "  'content/cat.jpg',  # cat\n",
    "  'content/dog.jpg',    # dog\n",
    "  'content/car.jpg',    # car\n",
    "  'content/plane.jpg'     # airplane\n",
    "]\n",
    "print('Loaded', len(IMAGE_URLS), 'sample image URLs.')\n",
    "\n",
    "HEAD_FUSION = 'mean'   # 可选: 'mean' | 'max' | 'min'\n",
    "START_LAYER = 0        # 从第几层开始做 rollout（可调以观察浅/深层差异）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_demo"
   },
   "outputs": [],
   "source": [
    "for i, url in enumerate(IMAGE_URLS):\n",
    "    print(f'\\n=== Image {i+1}: {url} ===')\n",
    "    img = load_image_from_url(url)\n",
    "    inputs = preprocess(img)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)  # outputs: last_hidden_state, pooler_output, attentions\n",
    "\n",
    "    # 1) 全局特征：CLS 或平均池化\n",
    "    cls_feat = outputs.last_hidden_state[:, 0]              # (B, D)\n",
    "    mean_feat = outputs.last_hidden_state.mean(dim=1)       # (B, D)\n",
    "    print('CLS feature shape:', tuple(cls_feat.shape), '| mean-pooled shape:', tuple(mean_feat.shape))\n",
    "\n",
    "    # 2) Attention Rollout\n",
    "    # outputs.attentions: list[L] of (B, heads, T, T)\n",
    "    attentions = [a.detach() for a in outputs.attentions]\n",
    "    cls_to_tokens = attention_rollout(attentions, head_fusion=HEAD_FUSION, start_layer=START_LAYER)  # (B, T)\n",
    "\n",
    "    # 去除 CLS 自身，剩下 patch token（DINOv2-small 默认 patch=14，输入518x518 => 37x37=1369 个patch + 1 cls => T=1370）\n",
    "    b, t = cls_to_tokens.shape\n",
    "    patch_scores = cls_to_tokens[:, 1:]  # (B, 37*37)\n",
    "    grid = int(np.sqrt(patch_scores.shape[1]))\n",
    "    attn_map = patch_scores.reshape(b, grid, grid).cpu().numpy()[0]\n",
    "    show_attention_on_image(img, attn_map)\n",
    "\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_cell"
   },
   "outputs": [],
   "source": [
    "# 可选：上传你自己的图片进行可视化（课堂时可用）\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # 选择一张或多张图片\n",
    "for fname in uploaded:\n",
    "    img = Image.open(io.BytesIO(uploaded[fname])).convert('RGB').resize((518, 518))\n",
    "    inputs = preprocess(img)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    attentions = [a.detach() for a in outputs.attentions]\n",
    "    cls_to_tokens = attention_rollout(attentions, head_fusion='mean', start_layer=0)\n",
    "    patch_scores = cls_to_tokens[:, 1:]\n",
    "    grid = int(np.sqrt(patch_scores.shape[1]))\n",
    "    attn_map = patch_scores.reshape(1, grid, grid).cpu().numpy()[0]\n",
    "    print('Visualizing:', fname)\n",
    "    show_attention_on_image(img, attn_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "notes"
   },
   "source": [
    "## 讲解要点速记\n",
    "- **Feature Extraction**：`last_hidden_state` 的 `CLS` 向量可作全局表征，或对 token 平均得到 `mean-pooled` 特征。\n",
    "- **Attention Rollout**：将每层注意力做 head 融合（mean/max/min），加上单位矩阵后归一化并逐层相乘，得到 CLS→各 token 的“信息流”强度。\n",
    "- **观察**：浅层更像边缘/纹理，深层更聚焦物体与上下文语义区域。课堂可切换 `START_LAYER`/`HEAD_FUSION` 展现差异。"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
