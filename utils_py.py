import torch
import numpy as np
from PIL import Image
import os
import requests
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt

def compute_similarity(features1, features2):
    """è®¡ç®—ä¸¤ä¸ªç‰¹å¾å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
    if features1.ndim == 1:
        features1 = features1.reshape(1, -1)
    if features2.ndim == 1:
        features2 = features2.reshape(1, -1)
    
    similarity = cosine_similarity(features1, features2)[0, 0]
    return float(similarity)

def download_sample_image(url, filename):
    """ä¸‹è½½ç¤ºä¾‹å›¾ç‰‡"""
    try:
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            with open(filename, 'wb') as f:
                f.write(response.content)
            return True
    except:
        pass
    return False

def create_sample_images():
    """åˆ›å»ºç¤ºä¾‹å›¾ç‰‡é›†åˆ"""
    # ç¤ºä¾‹å›¾ç‰‡URLåˆ—è¡¨ï¼ˆä½¿ç”¨ä¸€äº›å¸¸è§çš„æµ‹è¯•å›¾ç‰‡ï¼‰
    sample_urls = [
        "https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/PNG_transparency_demonstration_1.png/280px-PNG_transparency_demonstration_1.png",
        "https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Vd-Orig.png/256px-Vd-Orig.png",
    ]
    
    # åˆ›å»ºç¤ºä¾‹å›¾ç‰‡ç›®å½•
    os.makedirs("sample_images", exist_ok=True)
    
    # å¦‚æœæ— æ³•ä¸‹è½½ï¼Œåˆ›å»ºä¸€äº›ç®€å•çš„æµ‹è¯•å›¾ç‰‡
    sample_images = []
    
    # åˆ›å»ºå‡ ä¸ªç®€å•çš„æµ‹è¯•å›¾ç‰‡
    colors = [
        (255, 0, 0),    # çº¢è‰²
        (0, 255, 0),    # ç»¿è‰²
        (0, 0, 255),    # è“è‰²
        (255, 255, 0),  # é»„è‰²
        (255, 0, 255),  # ç´«è‰²
        (0, 255, 255),  # é’è‰²
    ]
    
    patterns = [
        "solid",      # çº¯è‰²
        "gradient",   # æ¸å˜
        "checkerboard", # æ£‹ç›˜
        "circles",    # åœ†å½¢
        "stripes",    # æ¡çº¹
        "dots",       # ç‚¹çŠ¶
    ]
    
    for i, (color, pattern) in enumerate(zip(colors, patterns)):
        img = create_pattern_image(color, pattern, size=(224, 224))
        filename = f"sample_images/sample_{i+1}_{pattern}.png"
        img.save(filename)
        sample_images.append(filename)
    
    return sample_images

def create_pattern_image(color, pattern, size=(224, 224)):
    """åˆ›å»ºå¸¦æœ‰ç‰¹å®šæ¨¡å¼çš„å›¾ç‰‡"""
    img = Image.new('RGB', size, color)
    pixels = img.load()
    
    if pattern == "gradient":
        for y in range(size[1]):
            factor = y / size[1]
            new_color = tuple(int(c * factor) for c in color)
            for x in range(size[0]):
                pixels[x, y] = new_color
    
    elif pattern == "checkerboard":
        square_size = 20
        for y in range(size[1]):
            for x in range(size[0]):
                if ((x // square_size) + (y // square_size)) % 2:
                    pixels[x, y] = (255 - color[0], 255 - color[1], 255 - color[2])
    
    elif pattern == "circles":
        center_x, center_y = size[0] // 2, size[1] // 2
        for y in range(size[1]):
            for x in range(size[0]):
                distance = ((x - center_x) ** 2 + (y - center_y) ** 2) ** 0.5
                if int(distance) % 30 < 15:
                    pixels[x, y] = (255 - color[0], 255 - color[1], 255 - color[2])
    
    elif pattern == "stripes":
        stripe_width = 15
        for y in range(size[1]):
            for x in range(size[0]):
                if (x // stripe_width) % 2:
                    pixels[x, y] = (255 - color[0], 255 - color[1], 255 - color[2])
    
    elif pattern == "dots":
        for y in range(0, size[1], 30):
            for x in range(0, size[0], 30):
                for dy in range(-5, 6):
                    for dx in range(-5, 6):
                        if 0 <= x + dx < size[0] and 0 <= y + dy < size[1]:
                            if dx*dx + dy*dy <= 25:  # åœ†å½¢ç‚¹
                                pixels[x + dx, y + dy] = (255 - color[0], 255 - color[1], 255 - color[2])
    
    return img

def load_sample_images(processor, model, sample_dir="sample_images"):
    """åŠ è½½ç¤ºä¾‹å›¾ç‰‡å¹¶æå–ç‰¹å¾"""
    # å¦‚æœç¤ºä¾‹å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
    if not os.path.exists(sample_dir):
        print("ğŸ“ åˆ›å»ºç¤ºä¾‹å›¾ç‰‡...")
        sample_paths = create_sample_images()
    else:
        sample_paths = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) 
                       if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        if not sample_paths:
            print("ğŸ“ åˆ›å»ºç¤ºä¾‹å›¾ç‰‡...")
            sample_paths = create_sample_images()
    
    images = []
    features = []
    
    print(f"ğŸ–¼ï¸  åŠ è½½ {len(sample_paths)} å¼ ç¤ºä¾‹å›¾ç‰‡...")
    
    for img_path in sample_paths:
        try:
            # åŠ è½½å›¾ç‰‡
            img = Image.open(img_path).convert('RGB')
            images.append(img)
            
            # æå–ç‰¹å¾
            inputs = processor(images=img, return_tensors="pt")
            with torch.no_grad():
                outputs = model(**inputs)
                # ä½¿ç”¨CLS tokenä½œä¸ºå…¨å±€ç‰¹å¾
                feature = outputs.last_hidden_state[:, 0, :].numpy()
                features.append(feature)
        
        except Exception as e:
            print(f"âŒ åŠ è½½å›¾ç‰‡å¤±è´¥ {img_path}: {e}")
            continue
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(images)} å¼ å›¾ç‰‡")
    return images, features

def visualize_features(features, labels=None, method='PCA', title="ç‰¹å¾å¯è§†åŒ–"):
    """å¯è§†åŒ–é«˜ç»´ç‰¹å¾"""
    from sklearn.decomposition import PCA
    from sklearn.manifold import TSNE
    
    features_array = np.vstack(features) if isinstance(features, list) else features
    
    # é™ç»´
    if method == 'PCA':
        reducer = PCA(n_components=2)
        reduced_features = reducer.fit_transform(features_array)
    elif method == 't-SNE':
        reducer = TSNE(n_components=2, random_state=42, perplexity=min(30, len(features_array)-1))
        reduced_features = reducer.fit_transform(features_array)
    
    # ç»˜å›¾
    plt.figure(figsize=(10, 8))
    if labels is None:
        plt.scatter(reduced_features[:, 0], reduced_features[:, 1], alpha=0.7)
        for i, (x, y) in enumerate(reduced_features):
            plt.annotate(f'{i}', (x, y), xytext=(5, 5), textcoords='offset points')
    else:
        unique_labels = list(set(labels))
        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))
        
        for label, color in zip(unique_labels, colors):
            mask = np.array(labels) == label
            plt.scatter(reduced_features[mask, 0], reduced_features[mask, 1], 
                       c=[color], label=label, alpha=0.7)
    
    plt.title(title)
    plt.xlabel(f'{method} 1')
    plt.ylabel(f'{method} 2')
    if labels is not None:
        plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    return plt.gcf()

def batch_extract_features(images, processor, model, batch_size=8):
    """æ‰¹é‡æå–å›¾ç‰‡ç‰¹å¾"""
    features = []
    model.eval()
    
    for i in range(0, len(images), batch_size):
        batch_images = images[i:i+batch_size]
        
        # é¢„å¤„ç†æ‰¹é‡å›¾ç‰‡
        inputs = processor(images=batch_images, return_tensors="pt")
        
        # æå–ç‰¹å¾
        with torch.no_grad():
            outputs = model(**inputs)
            batch_features = outputs.last_hidden_state[:, 0, :].numpy()
            features.extend(batch_features)
    
    return np.array(features)

def save_results(results, filename="demo_results.txt"):
    """ä¿å­˜æ¼”ç¤ºç»“æœ"""
    with open(filename, 'w', encoding='utf-8') as f:
        f.write("DINOv2 è¯¾å ‚æ¼”ç¤ºç»“æœ\n")
        f.write("=" * 50 + "\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {np.datetime64('now')}\n\n")
        
        for key, value in results.items():
            f.write(f"{key}:\n{value}\n\n")
    
    print(f"âœ… ç»“æœå·²ä¿å­˜åˆ° {filename}")

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦å®‰è£…"""
    required_packages = [
        'torch', 'transformers', 'gradio', 'scikit-learn', 
        'matplotlib', 'numpy', 'PIL', 'requests'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print("âŒ ç¼ºå°‘ä»¥ä¸‹ä¾èµ–åŒ…:")
        for pkg in missing_packages:
            print(f"   - {pkg}")
        print("\nè¯·è¿è¡Œ: pip install -r requirements.txt")
        return False
    else:
        print("âœ… æ‰€æœ‰ä¾èµ–åŒ…éƒ½å·²å®‰è£…")
        return True

if __name__ == "__main__":
    # æµ‹è¯•å·¥å…·å‡½æ•°
    print("ğŸ§ª æµ‹è¯•å·¥å…·å‡½æ•°...")
    
    # æ£€æŸ¥ä¾èµ–
    check_dependencies()
    
    # åˆ›å»ºæµ‹è¯•å›¾ç‰‡
    test_images = create_sample_images()
    print(f"ğŸ“¸ åˆ›å»ºäº† {len(test_images)} å¼ æµ‹è¯•å›¾ç‰‡")
    
    print("âœ… å·¥å…·å‡½æ•°æµ‹è¯•å®Œæˆ!")