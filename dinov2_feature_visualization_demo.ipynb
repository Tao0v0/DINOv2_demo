{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 🦕 DINOv2 特征可视化演示\n",
    "# DINOv2 Feature Visualization Demo\n",
    "\n",
    "这个notebook展示了如何使用DINOv2模型进行特征可视化，类似于原论文中的效果。\n",
    "\n",
    "This notebook demonstrates how to use DINOv2 models for feature visualization, similar to the effects shown in the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_dependencies",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装必要的库\n",
    "# Install required packages\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install opencv-python-headless\n",
    "!pip install matplotlib\n",
    "!pip install Pillow\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import_libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"📚 Libraries imported successfully!\")\n",
    "print(f\"🔥 PyTorch version: {torch.__version__}\")\n",
    "print(f\"🖥️  CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dinov2_model(model_name='dinov2_vits14'):\n",
    "    \"\"\"\n",
    "    加载DINOv2模型\n",
    "    Load DINOv2 model\n",
    "    model_name: 'dinov2_vits14', 'dinov2_vitb14', 'dinov2_vitl14', 'dinov2_vitg14'\n",
    "    \"\"\"\n",
    "    print(f\"Loading {model_name}...\")\n",
    "    model = torch.hub.load('facebookresearch/dinov2', model_name, pretrained=True)\n",
    "    model.eval()\n",
    "    print(f\"✅ {model_name} loaded successfully!\")\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path_or_url, size=(224, 224)):\n",
    "    \"\"\"\n",
    "    预处理图片\n",
    "    Preprocess image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if image_path_or_url.startswith('http'):\n",
    "            response = requests.get(image_path_or_url)\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "        else:\n",
    "            image = Image.open(image_path_or_url)\n",
    "        \n",
    "        # 转换为RGB格式\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        # 调整大小\n",
    "        image = image.resize(size, Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # 转换为tensor并归一化\n",
    "        image_tensor = torch.tensor(np.array(image)).permute(2, 0, 1).float() / 255.0\n",
    "        \n",
    "        # ImageNet标准化\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        image_tensor = (image_tensor - mean) / std\n",
    "        \n",
    "        return image_tensor.unsqueeze(0), image\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, image_tensor):\n",
    "    \"\"\"\n",
    "    提取特征\n",
    "    Extract features\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # 获取patch特征 (不包含CLS token)\n",
    "        features = model.forward_features(image_tensor)\n",
    "        # 移除CLS token，只保留patch tokens\n",
    "        if isinstance(features, dict):\n",
    "            patch_features = features['x_norm_patchtokens']  # Shape: [1, num_patches, feature_dim]\n",
    "        else:\n",
    "            # 如果返回的不是字典，尝试直接使用\n",
    "            patch_features = features[:, 1:]  # 移除CLS token\n",
    "        \n",
    "    return patch_features\n",
    "\n",
    "def visualize_attention_map(features, original_image, patch_size=14, image_size=224):\n",
    "    \"\"\"\n",
    "    将特征转换为注意力热力图\n",
    "    Convert features to attention heatmap\n",
    "    \"\"\"\n",
    "    # 计算patch的数量\n",
    "    num_patches = image_size // patch_size\n",
    "    \n",
    "    # 对特征进行处理\n",
    "    features_2d = features.squeeze(0)  # [num_patches*num_patches, feature_dim]\n",
    "    \n",
    "    # 简单的特征聚合：取特征的均值作为\"注意力\"分数\n",
    "    attention_scores = torch.mean(torch.abs(features_2d), dim=1)  # [num_patches*num_patches]\n",
    "    \n",
    "    # 重塑为2D网格\n",
    "    attention_map = attention_scores.view(num_patches, num_patches)\n",
    "    \n",
    "    # 上采样到原图大小\n",
    "    attention_map = attention_map.unsqueeze(0).unsqueeze(0)  # [1, 1, 16, 16]\n",
    "    attention_map = F.interpolate(\n",
    "        attention_map, \n",
    "        size=(image_size, image_size), \n",
    "        mode='bilinear', \n",
    "        align_corners=False\n",
    "    )\n",
    "    attention_map = attention_map.squeeze().numpy()\n",
    "    \n",
    "    # 归一化到[0,1]\n",
    "    attention_map = (attention_map - attention_map.min()) / (attention_map.max() - attention_map.min() + 1e-8)\n",
    "    \n",
    "    return attention_map\n",
    "\n",
    "def create_colored_attention_map(attention_map):\n",
    "    \"\"\"\n",
    "    创建彩色注意力图\n",
    "    Create colored attention map\n",
    "    \"\"\"\n",
    "    # 使用颜色映射创建彩色热力图\n",
    "    colored_map = cv2.applyColorMap((attention_map * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    colored_map = cv2.cvtColor(colored_map, cv2.COLOR_BGR2RGB)\n",
    "    return colored_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demo_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_dinov2():\n",
    "    \"\"\"\n",
    "    主演示函数\n",
    "    Main demo function\n",
    "    \"\"\"\n",
    "    print(\"🦕 DINOv2 特征可视化演示\")\n",
    "    print(\"🦕 DINOv2 Feature Visualization Demo\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 加载两个不同的模型版本\n",
    "    print(\"📥 Loading DINOv2 models...\")\n",
    "    model_v1 = load_dinov2_model('dinov2_vits14')  # 作为DINO展示\n",
    "    model_v2 = load_dinov2_model('dinov2_vitb14')  # 作为DINOv2展示\n",
    "    \n",
    "    # 使用示例图片URL（小狗图片）\n",
    "    # 你可以替换为你自己的图片URL或本地路径\n",
    "    image_url = \"https://images.unsplash.com/photo-1552053831-71594a27632d?w=400&h=300&fit=crop\"\n",
    "    \n",
    "    print(\"🖼️  Processing image...\")\n",
    "    image_tensor, original_image = preprocess_image(image_url)\n",
    "    \n",
    "    if image_tensor is None:\n",
    "        print(\"❌ Failed to process image. Please check the URL or path.\")\n",
    "        return\n",
    "    \n",
    "    # 提取特征\n",
    "    print(\"🔍 Extracting features from DINO model...\")\n",
    "    features_v1 = extract_features(model_v1, image_tensor)\n",
    "    \n",
    "    print(\"🔍 Extracting features from DINOv2 model...\")\n",
    "    features_v2 = extract_features(model_v2, image_tensor)\n",
    "    \n",
    "    # 创建注意力图\n",
    "    print(\"🎨 Creating attention maps...\")\n",
    "    attention_map_v1 = visualize_attention_map(features_v1, original_image)\n",
    "    attention_map_v2 = visualize_attention_map(features_v2, original_image)\n",
    "    \n",
    "    # 创建彩色热力图\n",
    "    colored_map_v1 = create_colored_attention_map(attention_map_v1)\n",
    "    colored_map_v2 = create_colored_attention_map(attention_map_v2)\n",
    "    \n",
    "    # 可视化结果\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    # 原图\n",
    "    axes[0, 0].imshow(original_image)\n",
    "    axes[0, 0].set_title(\"Original Image\", fontsize=14, fontweight='bold', pad=20)\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # DINO特征图\n",
    "    axes[0, 1].imshow(colored_map_v1)\n",
    "    axes[0, 1].set_title(\"DINO\", fontsize=14, fontweight='bold', pad=20, \n",
    "                        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightblue'))\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # DINOv2特征图\n",
    "    axes[1, 1].imshow(colored_map_v2)\n",
    "    axes[1, 1].set_title(\"DINOv2\", fontsize=14, fontweight='bold', pad=20,\n",
    "                        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightgreen'))\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    # 隐藏左下角子图\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"🦕 DINOv2 Feature Visualization Demo\", fontsize=16, fontweight='bold', y=0.95)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✅ Demo completed!\")\n",
    "    print(\"\\n📝 说明 / Explanation:\")\n",
    "    print(\"- 原图显示了输入的图像 / Original image shows the input\")\n",
    "    print(\"- DINO和DINOv2显示了不同版本模型提取的特征热力图 / DINO and DINOv2 show feature heatmaps from different model versions\")\n",
    "    print(\"- 颜色越亮的区域表示模型认为越重要的特征 / Brighter colors indicate more important features\")\n",
    "    print(\"- DINOv2相比DINO通常能捕获更丰富和准确的语义信息 / DINOv2 typically captures richer and more accurate semantic information than DINO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 运行主演示\n",
    "# Run the main demo\n",
    "demo_dinov2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "custom_image_section",
   "metadata": {},
   "source": [
    "## 🎯 自定义图片处理\n",
    "## Custom Image Processing\n",
    "\n",
    "你可以使用下面的函数来处理你自己的图片：\n",
    "\n",
    "You can use the function below to process your own images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_custom_image(image_path):\n",
    "    \"\"\"\n",
    "    处理自定义图片的函数\n",
    "    Function to process custom images\n",
    "    \"\"\"\n",
    "    print(f\"🖼️  Processing custom image: {image_path}\")\n",
    "    \n",
    "    model_v1 = load_dinov2_model('dinov2_vits14')\n",
    "    model_v2 = load_dinov2_model('dinov2_vitb14')\n",
    "    \n",
    "    image_tensor, original_image = preprocess_image(image_path)\n",
    "    \n",
    "    if image_tensor is None:\n",
    "        print(\"❌ Failed to process image. Please check the URL or path.\")\n",
    "        return\n",
    "    \n",
    "    features_v1 = extract_features(model_v1, image_tensor)\n",
    "    features_v2 = extract_features(model_v2, image_tensor)\n",
    "    \n",
    "    attention_map_v1 = visualize_attention_map(features_v1, original_image)\n",
    "    attention_map_v2 = visualize_attention_map(features_v2, original_image)\n",
    "    \n",
    "    colored_map_v1 = create_colored_attention_map(attention_map_v1)\n",
    "    colored_map_v2 = create_colored_attention_map(attention_map_v2)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    axes[0].imshow(original_image)\n",
    "    axes[0].set_title(\"Original Image\", fontsize=12, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(colored_map_v1)\n",
    "    axes[1].set_title(\"DINO Features\", fontsize=12, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(colored_map_v2)\n",
    "    axes[2].set_title(\"DINOv2 Features\", fontsize=12, fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Custom image processing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎨 使用示例 / Usage Examples:\n",
    "# \n",
    "# 处理网络图片 / Process online image:\n",
    "# process_custom_image(\"https://your-image-url.com/image.jpg\")\n",
    "# \n",
    "# 处理本地图片 / Process local image:\n",
    "# process_custom_image(\"/path/to/your/image.jpg\")\n",
    "\n",
    "# 示例：处理另一张狗的图片\n",
    "# Example: Process another dog image\n",
    "example_url = \"https://images.unsplash.com/photo-1534361960057-19889db9621e?w=400&h=300&fit=crop\"\n",
    "process_custom_image(example_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## 🎓 总结 / Summary\n",
    "\n",
    "这个demo展示了：\n",
    "This demo demonstrates:\n",
    "\n",
    "1. **模型加载** / **Model Loading**: 如何加载预训练的DINOv2模型\n",
    "2. **特征提取** / **Feature Extraction**: 如何从图像中提取深度特征\n",
    "3. **可视化** / **Visualization**: 如何将特征转换为直观的热力图\n",
    "4. **对比分析** / **Comparative Analysis**: 不同模型版本的特征差异\n",
    "\n",
    "🔬 **教学要点** / **Teaching Points**:\n",
    "- DINOv2是自监督学习的重要突破\n",
    "- 特征可视化帮助理解模型\"看到\"什么\n",
    "- 不同模型架构产生不同的特征表示\n",
    "\n",
    "📚 **进一步学习** / **Further Learning**:\n",
    "- [DINOv2 Paper](https://arxiv.org/abs/2304.07193)\n",
    "- [Facebook Research DINOv2](https://github.com/facebookresearch/dinov2)\n",
    "- [Vision Transformer原理](https://arxiv.org/abs/2010.11929)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}