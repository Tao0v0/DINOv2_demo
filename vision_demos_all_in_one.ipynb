{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e2563ae",
   "metadata": {},
   "source": [
    "\n",
    "# 🎬 Vision Classroom Demos (All-in-One): DINOv2 + SAM‑2\n",
    "\n",
    "此 Notebook 集成两个课堂演示：\n",
    "\n",
    "- **DINOv2**：自监督视觉表征 → 聚类可视化 + 最近邻检索\n",
    "- **SAM‑2**（脚手架/可选）：交互式分割（需模型权重，演示区提供占位与说明）\n",
    "\n",
    "> 建议方式：把此 `.ipynb` 上传到 GitHub，然后在 `README` 放一个 **Open in Colab** 按钮，课堂上一键打开运行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e2254b",
   "metadata": {},
   "source": [
    "## 0. 环境安装与检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip -q install --upgrade timm torchvision scikit-learn pillow matplotlib\n",
    "\n",
    "import torch, timm, os, io, requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from timm.data import resolve_data_config, create_transform\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"timm :\", timm.__version__)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba09fdb",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Part A — DINOv2：特征可视化 & 最近邻检索（可直接运行 ✅）\n",
    "\n",
    "目标：\n",
    "1. 提取多张图片的 DINOv2 表征，并用 **PCA** 做二维可视化（同类更接近）。\n",
    "2. 选一张图做 **最近邻检索**（用余弦相似度找最像的几张）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d41541",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) 加载 DINOv2（timm 提供的预训练权重，推荐 vit_small 变体以加快推理）\n",
    "model = timm.create_model(\"vit_small_patch14_dinov2\", pretrained=True)\n",
    "model.eval().to(device)\n",
    "\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "print(\"Transform config:\", config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39acf852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) 准备演示图片：可以替换为你自己的 URL 或本地路径\n",
    "IMAGE_URLS = [
    "/content/cat.jpg",
    "/content/dog.jpg",
    "/content/car.jpg",
    "/content/plane.jpg",
    ]
     \n",
    "\n",
    "def load_image(path_or_url):\n",
    "    if path_or_url.startswith(\"http\"):\n",
    "        r = requests.get(path_or_url, timeout=15)\n",
    "        r.raise_for_status()\n",
    "        img = Image.open(io.BytesIO(r.content)).convert(\"RGB\")\n",
    "    else:\n",
    "        img = Image.open(path_or_url).convert(\"RGB\")\n",
    "    return img\n",
    "\n",
    "images = [load_image(u) for u in IMAGE_URLS]\n",
    "print(f\"Loaded {len(images)} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20726532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) 提取特征：使用 forward_head(..., pre_logits=True) 获取分类头前的表征\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_feature(img: Image.Image):\n",
    "    x = transform(img).unsqueeze(0).to(device)         # [1, C, H, W]\n",
    "    feats = model.forward_features(x)                  # dict/tensor by model\n",
    "    emb = model.forward_head(feats, pre_logits=True)   # [1, D]\n",
    "    emb = F.normalize(emb, dim=-1)                     # 归一化便于余弦相似度\n",
    "    return emb.squeeze(0).cpu().numpy()                # [D]\n",
    "\n",
    "features = np.stack([extract_feature(img) for img in images], axis=0)  # [N, D]\n",
    "print(\"Feature shape:\", features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) PCA 2D 可视化\n",
    "pca = PCA(n_components=2, random_state=0)\n",
    "xy = pca.fit_transform(features)  # [N, 2]\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(xy[:, 0], xy[:, 1], s=80)\n",
    "for i, (x, y) in enumerate(xy):\n",
    "    plt.text(x + 0.01, y + 0.01, f\"img{i}\", fontsize=10)\n",
    "plt.title(\"DINOv2 Features (PCA 2D)\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d68da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) 最近邻检索：给定 query，展示 Top-k 相似图片\n",
    "def show_img(img, title=None):\n",
    "    plt.imshow(img); plt.axis(\"off\")\n",
    "    if title: plt.title(title)\n",
    "\n",
    "def knn_retrieval(query_idx=0, topk=3):\n",
    "    sims = cosine_similarity(features[query_idx:query_idx+1], features)[0]  # [N]\n",
    "    order = np.argsort(-sims)  # 从大到小\n",
    "    print(f\"[Query] img{query_idx}  → Top-{topk} similar indices:\", order[:topk+1])\n",
    "\n",
    "    cols = topk + 1\n",
    "    plt.figure(figsize=(3.2*cols, 3.5))\n",
    "    plt.subplot(1, cols, 1); show_img(images[query_idx], title=f\"Query (img{query_idx})\")\n",
    "    shown = 1\n",
    "    for idx in order:\n",
    "        if idx == query_idx: \n",
    "            continue\n",
    "        plt.subplot(1, cols, shown+1)\n",
    "        show_img(images[idx], title=f\"Top{shown} (img{idx})\\ncos={sims[idx]:.3f}\")\n",
    "        shown += 1\n",
    "        if shown > topk: \n",
    "            break\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# 试一试：把 0 改成 1/2/3 等，看检索结果\n",
    "knn_retrieval(query_idx=0, topk=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f50bd",
   "metadata": {},
   "source": [
    "\n",
    "> **课堂讲解建议（~3分钟）**  \n",
    "> 1. 说明 DINOv2 是自监督视觉表征；  \n",
    "> 2. 展示 PCA 图：同类样本更靠近；  \n",
    "> 3. 运行 KNN 检索，多换几张 query 看 Top‑k；  \n",
    "> 4. 鼓励同学上传现场图片做即场检索。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f121d706",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Part B — SAM‑2：交互式分割（脚手架 / 可选）\n",
    "\n",
    "> 说明：SAM‑2 需要加载较大的模型权重（数百 MB），为了让本 Notebook 保持单文件、小体积、即开即用，下面提供 **占位与演示框架**：\n",
    ">\n",
    "> - 你只需将官方 **checkpoint 下载链接** 填入下方变量，或把权重放到 Colab/本地路径；\n",
    "> - 运行安装与加载单元，即可用点/框提示完成分割；\n",
    "> - 若课堂网络不稳定，建议提前在 Colab 里预运行并缓存（或录屏作为备份）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f02a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) （可选）安装 SAM‑2\n",
    "# 提示：如果你已有运行环境，可注释掉此步\n",
    "# 尝试从 GitHub 安装（如失败，请改用你本地/内网镜像或提前装好环境）\n",
    "try:\n",
    "    import sam2  # noqa: F401  # 若已安装则跳过\n",
    "    print(\"sam2 已存在，跳过安装。\")\n",
    "except Exception as e:\n",
    "    print(\"准备安装 sam2（如失败，请根据你的环境调整安装方式）\")\n",
    "    !pip -q install 'git+https://github.com/facebookresearch/sam2.git' || true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de09e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) 设置权重路径/URL（请替换为官方 checkpoints 的直链，或上传到 /content/ 目录）\n",
    "SAM2_CKPT_URL = \"REPLACE_WITH_OFFICIAL_SAM2_CHECKPOINT_URL\"  # TODO: 替换为真实链接\n",
    "SAM2_CKPT_PATH = \"/content/sam2_checkpoint.pt\"               # 下载保存路径（可改）\n",
    "\n",
    "# 如果你已把权重上传到 Colab 或本地，直接把 SAM2_CKPT_PATH 指向该文件即可，跳过下载。\n",
    "DOWNLOAD_IF_URL_SET = SAM2_CKPT_URL.startswith(\"http\")\n",
    "if DOWNLOAD_IF_URL_SET:\n",
    "    import requests, io\n",
    "    from pathlib import Path\n",
    "    try:\n",
    "        print(\"Downloading SAM‑2 checkpoint ...\")\n",
    "        r = requests.get(SAM2_CKPT_URL, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        Path(SAM2_CKPT_PATH).write_bytes(r.content)\n",
    "        print(\"Checkpoint saved to:\", SAM2_CKPT_PATH)\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ 下载失败：\", e)\n",
    "        print(\"请手动上传权重到\", SAM2_CKPT_PATH, \"或提供可访问的下载链接。\")\n",
    "else:\n",
    "    print(\"跳过下载，使用本地路径：\", SAM2_CKPT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) 载入模型（API 随版本可能有差异，以下为伪代码式示例框架，便于你替换为实际调用）\n",
    "# 注意：请根据官方 README 示例替换为对应的构建/加载接口。\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def overlay_mask(image_pil, mask_bool, alpha=0.6):\n",
    "    img = np.array(image_pil).astype(np.float32)\n",
    "    mask = mask_bool.astype(np.float32)[..., None]\n",
    "    color = np.array([0, 255, 0], dtype=np.float32)  # 绿色遮罩\n",
    "    vis = img * (1 - alpha * mask) + color * (alpha * mask)\n",
    "    return vis.astype(np.uint8)\n",
    "\n",
    "# 占位：加载任意一张图片\n",
    "IMG_URL = \"https://images.pexels.com/photos/1108099/pexels-photo-1108099.jpeg\"\n",
    "img = Image.open(requests.get(IMG_URL, stream=True).raw).convert(\"RGB\")\n",
    "\n",
    "print(\"占位提示：请参考官方 API，将 SAM‑2 predictor 初始化与推理代码粘贴到此处。\")\n",
    "print(\"示例伪代码：\")\n",
    "print(\"\"\"\n",
    "from sam2 import build_sam2_predictor  # 请以实际 API 为准\n",
    "predictor = build_sam2_predictor(checkpoint=SAM2_CKPT_PATH, device=device)\n",
    "\n",
    "# 以单点提示为例：point_coords: np.ndarray[[x, y]]\n",
    "point_coords = np.array([[320, 240]]); point_labels = np.array([1])  # 正提示点\n",
    "masks = predictor.predict(image=img, point_coords=point_coords, point_labels=point_labels)\n",
    "\"\"\")\n",
    "\n",
    "# 下面展示如何把 mask 可视化到原图（masks[0] 为 bool/0-1 掩膜）\n",
    "# masks = predictor.predict(...)\n",
    "# vis = overlay_mask(img, masks[0])\n",
    "# plt.figure(figsize=(6,4)); plt.imshow(vis); plt.axis(\"off\"); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4)); plt.imshow(img); plt.title(\"占位图像（请在上方集成 SAM‑2 推理）\"); plt.axis(\"off\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3daca1a",
   "metadata": {},
   "source": [
    "\n",
    "> **将来你只需做两件事：**  \n",
    "> 1. 把 `SAM2_CKPT_URL` 换成官方 checkpoint 的可下载直链（或把权重上传并设置 `SAM2_CKPT_PATH`）。  \n",
    "> 2. 将你所用版本的 **官方 Predictor 初始化与 `predict` 示例** 粘贴到上面的占位代码处，并把 `masks` 可视化即可。  \n",
    ">\n",
    "> 这样，本 Notebook 仍保持单文件结构，便于 **“一个文件上 GitHub”** 与 **课堂一键演示**。\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
