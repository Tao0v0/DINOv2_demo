{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e2563ae",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ¬ Vision Classroom Demos (All-in-One): DINOv2 + SAMâ€‘2\n",
    "\n",
    "æ­¤ Notebook é›†æˆä¸¤ä¸ªè¯¾å ‚æ¼”ç¤ºï¼š\n",
    "\n",
    "- **DINOv2**ï¼šè‡ªç›‘ç£è§†è§‰è¡¨å¾ â†’ èšç±»å¯è§†åŒ– + æœ€è¿‘é‚»æ£€ç´¢\n",
    "- **SAMâ€‘2**ï¼ˆè„šæ‰‹æ¶/å¯é€‰ï¼‰ï¼šäº¤äº’å¼åˆ†å‰²ï¼ˆéœ€æ¨¡å‹æƒé‡ï¼Œæ¼”ç¤ºåŒºæä¾›å ä½ä¸è¯´æ˜ï¼‰\n",
    "\n",
    "> å»ºè®®æ–¹å¼ï¼šæŠŠæ­¤ `.ipynb` ä¸Šä¼ åˆ° GitHubï¼Œç„¶ååœ¨ `README` æ”¾ä¸€ä¸ª **Open in Colab** æŒ‰é’®ï¼Œè¯¾å ‚ä¸Šä¸€é”®æ‰“å¼€è¿è¡Œã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e2254b",
   "metadata": {},
   "source": [
    "## 0. ç¯å¢ƒå®‰è£…ä¸æ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip -q install --upgrade timm torchvision scikit-learn pillow matplotlib\n",
    "\n",
    "import torch, timm, os, io, requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from timm.data import resolve_data_config, create_transform\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"timm :\", timm.__version__)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba09fdb",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Part A â€” DINOv2ï¼šç‰¹å¾å¯è§†åŒ– & æœ€è¿‘é‚»æ£€ç´¢ï¼ˆå¯ç›´æ¥è¿è¡Œ âœ…ï¼‰\n",
    "\n",
    "ç›®æ ‡ï¼š\n",
    "1. æå–å¤šå¼ å›¾ç‰‡çš„ DINOv2 è¡¨å¾ï¼Œå¹¶ç”¨ **PCA** åšäºŒç»´å¯è§†åŒ–ï¼ˆåŒç±»æ›´æ¥è¿‘ï¼‰ã€‚\n",
    "2. é€‰ä¸€å¼ å›¾åš **æœ€è¿‘é‚»æ£€ç´¢**ï¼ˆç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ‰¾æœ€åƒçš„å‡ å¼ ï¼‰ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d41541",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) åŠ è½½ DINOv2ï¼ˆtimm æä¾›çš„é¢„è®­ç»ƒæƒé‡ï¼Œæ¨è vit_small å˜ä½“ä»¥åŠ å¿«æ¨ç†ï¼‰\n",
    "model = timm.create_model(\"vit_small_patch14_dinov2\", pretrained=True)\n",
    "model.eval().to(device)\n",
    "\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "print(\"Transform config:\", config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39acf852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) å‡†å¤‡æ¼”ç¤ºå›¾ç‰‡ï¼šå¯ä»¥æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ URL æˆ–æœ¬åœ°è·¯å¾„\n",
    "IMAGE_URLS = [\n",
    "    \"/content/cat.jpg\",    # çŒ«\n",
    "    \"/content/dog.jpg\",    # ç‹—\n",
    "    \"/content/car.jpg\",    # æ±½è½¦\n",
    "    \"/content/plane.jpg\",  # é£æœº\n",
    "]\n",
    "\n",
    "def load_image(path_or_url):\n",
    "    if path_or_url.startswith(\"http\"):\n",
    "        r = requests.get(path_or_url, timeout=15)\n",
    "        r.raise_for_status()\n",
    "        img = Image.open(io.BytesIO(r.content)).convert(\"RGB\")\n",
    "    else:\n",
    "        img = Image.open(path_or_url).convert(\"RGB\")\n",
    "    return img\n",
    "\n",
    "images = [load_image(u) for u in IMAGE_URLS]\n",
    "print(f\"Loaded {len(images)} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20726532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) æå–ç‰¹å¾ï¼šä½¿ç”¨ forward_head(..., pre_logits=True) è·å–åˆ†ç±»å¤´å‰çš„è¡¨å¾\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_feature(img: Image.Image):\n",
    "    x = transform(img).unsqueeze(0).to(device)         # [1, C, H, W]\n",
    "    feats = model.forward_features(x)                  # dict/tensor by model\n",
    "    emb = model.forward_head(feats, pre_logits=True)   # [1, D]\n",
    "    emb = F.normalize(emb, dim=-1)                     # å½’ä¸€åŒ–ä¾¿äºä½™å¼¦ç›¸ä¼¼åº¦\n",
    "    return emb.squeeze(0).cpu().numpy()                # [D]\n",
    "\n",
    "features = np.stack([extract_feature(img) for img in images], axis=0)  # [N, D]\n",
    "print(\"Feature shape:\", features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) PCA 2D å¯è§†åŒ–\n",
    "pca = PCA(n_components=2, random_state=0)\n",
    "xy = pca.fit_transform(features)  # [N, 2]\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(xy[:, 0], xy[:, 1], s=80)\n",
    "for i, (x, y) in enumerate(xy):\n",
    "    plt.text(x + 0.01, y + 0.01, f\"img{i}\", fontsize=10)\n",
    "plt.title(\"DINOv2 Features (PCA 2D)\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d68da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) æœ€è¿‘é‚»æ£€ç´¢ï¼šç»™å®š queryï¼Œå±•ç¤º Top-k ç›¸ä¼¼å›¾ç‰‡\n",
    "def show_img(img, title=None):\n",
    "    plt.imshow(img); plt.axis(\"off\")\n",
    "    if title: plt.title(title)\n",
    "\n",
    "def knn_retrieval(query_idx=0, topk=3):\n",
    "    sims = cosine_similarity(features[query_idx:query_idx+1], features)[0]  # [N]\n",
    "    order = np.argsort(-sims)  # ä»å¤§åˆ°å°\n",
    "    print(f\"[Query] img{query_idx}  â†’ Top-{topk} similar indices:\", order[:topk+1])\n",
    "\n",
    "    cols = topk + 1\n",
    "    plt.figure(figsize=(3.2*cols, 3.5))\n",
    "    plt.subplot(1, cols, 1); show_img(images[query_idx], title=f\"Query (img{query_idx})\")\n",
    "    shown = 1\n",
    "    for idx in order:\n",
    "        if idx == query_idx: \n",
    "            continue\n",
    "        plt.subplot(1, cols, shown+1)\n",
    "        show_img(images[idx], title=f\"Top{shown} (img{idx})\\ncos={sims[idx]:.3f}\")\n",
    "        shown += 1\n",
    "        if shown > topk: \n",
    "            break\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# è¯•ä¸€è¯•ï¼šæŠŠ 0 æ”¹æˆ 1/2/3 ç­‰ï¼Œçœ‹æ£€ç´¢ç»“æœ\n",
    "knn_retrieval(query_idx=0, topk=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f50bd",
   "metadata": {},
   "source": [
    "\n",
    "> **è¯¾å ‚è®²è§£å»ºè®®ï¼ˆ~3åˆ†é’Ÿï¼‰**  \n",
    "> 1. è¯´æ˜ DINOv2 æ˜¯è‡ªç›‘ç£è§†è§‰è¡¨å¾ï¼›  \n",
    "> 2. å±•ç¤º PCA å›¾ï¼šåŒç±»æ ·æœ¬æ›´é è¿‘ï¼›  \n",
    "> 3. è¿è¡Œ KNN æ£€ç´¢ï¼Œå¤šæ¢å‡ å¼  query çœ‹ Topâ€‘kï¼›  \n",
    "> 4. é¼“åŠ±åŒå­¦ä¸Šä¼ ç°åœºå›¾ç‰‡åšå³åœºæ£€ç´¢ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f121d706",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Part B â€” SAMâ€‘2ï¼šäº¤äº’å¼åˆ†å‰²ï¼ˆè„šæ‰‹æ¶ / å¯é€‰ï¼‰\n",
    "\n",
    "> è¯´æ˜ï¼šSAMâ€‘2 éœ€è¦åŠ è½½è¾ƒå¤§çš„æ¨¡å‹æƒé‡ï¼ˆæ•°ç™¾ MBï¼‰ï¼Œä¸ºäº†è®©æœ¬ Notebook ä¿æŒå•æ–‡ä»¶ã€å°ä½“ç§¯ã€å³å¼€å³ç”¨ï¼Œä¸‹é¢æä¾› **å ä½ä¸æ¼”ç¤ºæ¡†æ¶**ï¼š\n",
    ">\n",
    "> - ä½ åªéœ€å°†å®˜æ–¹ **checkpoint ä¸‹è½½é“¾æ¥** å¡«å…¥ä¸‹æ–¹å˜é‡ï¼Œæˆ–æŠŠæƒé‡æ”¾åˆ° Colab/æœ¬åœ°è·¯å¾„ï¼›\n",
    "> - è¿è¡Œå®‰è£…ä¸åŠ è½½å•å…ƒï¼Œå³å¯ç”¨ç‚¹/æ¡†æç¤ºå®Œæˆåˆ†å‰²ï¼›\n",
    "> - è‹¥è¯¾å ‚ç½‘ç»œä¸ç¨³å®šï¼Œå»ºè®®æå‰åœ¨ Colab é‡Œé¢„è¿è¡Œå¹¶ç¼“å­˜ï¼ˆæˆ–å½•å±ä½œä¸ºå¤‡ä»½ï¼‰ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f02a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) ï¼ˆå¯é€‰ï¼‰å®‰è£… SAMâ€‘2\n",
    "# æç¤ºï¼šå¦‚æœä½ å·²æœ‰è¿è¡Œç¯å¢ƒï¼Œå¯æ³¨é‡Šæ‰æ­¤æ­¥\n",
    "# å°è¯•ä» GitHub å®‰è£…ï¼ˆå¦‚å¤±è´¥ï¼Œè¯·æ”¹ç”¨ä½ æœ¬åœ°/å†…ç½‘é•œåƒæˆ–æå‰è£…å¥½ç¯å¢ƒï¼‰\n",
    "try:\n",
    "    import sam2  # noqa: F401  # è‹¥å·²å®‰è£…åˆ™è·³è¿‡\n",
    "    print(\"sam2 å·²å­˜åœ¨ï¼Œè·³è¿‡å®‰è£…ã€‚\")\n",
    "except Exception as e:\n",
    "    print(\"å‡†å¤‡å®‰è£… sam2ï¼ˆå¦‚å¤±è´¥ï¼Œè¯·æ ¹æ®ä½ çš„ç¯å¢ƒè°ƒæ•´å®‰è£…æ–¹å¼ï¼‰\")\n",
    "    !pip -q install 'git+https://github.com/facebookresearch/sam2.git' || true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de09e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) è®¾ç½®æƒé‡è·¯å¾„/URLï¼ˆè¯·æ›¿æ¢ä¸ºå®˜æ–¹ checkpoints çš„ç›´é“¾ï¼Œæˆ–ä¸Šä¼ åˆ° /content/ ç›®å½•ï¼‰\n",
    "SAM2_CKPT_URL = \"REPLACE_WITH_OFFICIAL_SAM2_CHECKPOINT_URL\"  # TODO: æ›¿æ¢ä¸ºçœŸå®é“¾æ¥\n",
    "SAM2_CKPT_PATH = \"/content/sam2_checkpoint.pt\"               # ä¸‹è½½ä¿å­˜è·¯å¾„ï¼ˆå¯æ”¹ï¼‰\n",
    "\n",
    "# å¦‚æœä½ å·²æŠŠæƒé‡ä¸Šä¼ åˆ° Colab æˆ–æœ¬åœ°ï¼Œç›´æ¥æŠŠ SAM2_CKPT_PATH æŒ‡å‘è¯¥æ–‡ä»¶å³å¯ï¼Œè·³è¿‡ä¸‹è½½ã€‚\n",
    "DOWNLOAD_IF_URL_SET = SAM2_CKPT_URL.startswith(\"http\")\n",
    "if DOWNLOAD_IF_URL_SET:\n",
    "    import requests, io\n",
    "    from pathlib import Path\n",
    "    try:\n",
    "        print(\"Downloading SAMâ€‘2 checkpoint ...\")\n",
    "        r = requests.get(SAM2_CKPT_URL, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        Path(SAM2_CKPT_PATH).write_bytes(r.content)\n",
    "        print(\"Checkpoint saved to:\", SAM2_CKPT_PATH)\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ ä¸‹è½½å¤±è´¥ï¼š\", e)\n",
    "        print(\"è¯·æ‰‹åŠ¨ä¸Šä¼ æƒé‡åˆ°\", SAM2_CKPT_PATH, \"æˆ–æä¾›å¯è®¿é—®çš„ä¸‹è½½é“¾æ¥ã€‚\")\n",
    "else:\n",
    "    print(\"è·³è¿‡ä¸‹è½½ï¼Œä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼š\", SAM2_CKPT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) è½½å…¥æ¨¡å‹ï¼ˆAPI éšç‰ˆæœ¬å¯èƒ½æœ‰å·®å¼‚ï¼Œä»¥ä¸‹ä¸ºä¼ªä»£ç å¼ç¤ºä¾‹æ¡†æ¶ï¼Œä¾¿äºä½ æ›¿æ¢ä¸ºå®é™…è°ƒç”¨ï¼‰\n",
    "# æ³¨æ„ï¼šè¯·æ ¹æ®å®˜æ–¹ README ç¤ºä¾‹æ›¿æ¢ä¸ºå¯¹åº”çš„æ„å»º/åŠ è½½æ¥å£ã€‚\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def overlay_mask(image_pil, mask_bool, alpha=0.6):\n",
    "    img = np.array(image_pil).astype(np.float32)\n",
    "    mask = mask_bool.astype(np.float32)[..., None]\n",
    "    color = np.array([0, 255, 0], dtype=np.float32)  # ç»¿è‰²é®ç½©\n",
    "    vis = img * (1 - alpha * mask) + color * (alpha * mask)\n",
    "    return vis.astype(np.uint8)\n",
    "\n",
    "# å ä½ï¼šåŠ è½½ä»»æ„ä¸€å¼ å›¾ç‰‡\n",
    "IMG_URL = \"https://images.pexels.com/photos/1108099/pexels-photo-1108099.jpeg\"\n",
    "img = Image.open(requests.get(IMG_URL, stream=True).raw).convert(\"RGB\")\n",
    "\n",
    "print(\"å ä½æç¤ºï¼šè¯·å‚è€ƒå®˜æ–¹ APIï¼Œå°† SAMâ€‘2 predictor åˆå§‹åŒ–ä¸æ¨ç†ä»£ç ç²˜è´´åˆ°æ­¤å¤„ã€‚\")\n",
    "print(\"ç¤ºä¾‹ä¼ªä»£ç ï¼š\")\n",
    "print(\"\"\"\n",
    "from sam2 import build_sam2_predictor  # è¯·ä»¥å®é™… API ä¸ºå‡†\n",
    "predictor = build_sam2_predictor(checkpoint=SAM2_CKPT_PATH, device=device)\n",
    "\n",
    "# ä»¥å•ç‚¹æç¤ºä¸ºä¾‹ï¼špoint_coords: np.ndarray[[x, y]]\n",
    "point_coords = np.array([[320, 240]]); point_labels = np.array([1])  # æ­£æç¤ºç‚¹\n",
    "masks = predictor.predict(image=img, point_coords=point_coords, point_labels=point_labels)\n",
    "\"\"\")\n",
    "\n",
    "# ä¸‹é¢å±•ç¤ºå¦‚ä½•æŠŠ mask å¯è§†åŒ–åˆ°åŸå›¾ï¼ˆmasks[0] ä¸º bool/0-1 æ©è†œï¼‰\n",
    "# masks = predictor.predict(...)\n",
    "# vis = overlay_mask(img, masks[0])\n",
    "# plt.figure(figsize=(6,4)); plt.imshow(vis); plt.axis(\"off\"); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4)); plt.imshow(img); plt.title(\"å ä½å›¾åƒï¼ˆè¯·åœ¨ä¸Šæ–¹é›†æˆ SAMâ€‘2 æ¨ç†ï¼‰\"); plt.axis(\"off\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3daca1a",
   "metadata": {},
   "source": [
    "\n",
    "> **å°†æ¥ä½ åªéœ€åšä¸¤ä»¶äº‹ï¼š**  \n",
    "> 1. æŠŠ `SAM2_CKPT_URL` æ¢æˆå®˜æ–¹ checkpoint çš„å¯ä¸‹è½½ç›´é“¾ï¼ˆæˆ–æŠŠæƒé‡ä¸Šä¼ å¹¶è®¾ç½® `SAM2_CKPT_PATH`ï¼‰ã€‚  \n",
    "> 2. å°†ä½ æ‰€ç”¨ç‰ˆæœ¬çš„ **å®˜æ–¹ Predictor åˆå§‹åŒ–ä¸ `predict` ç¤ºä¾‹** ç²˜è´´åˆ°ä¸Šé¢çš„å ä½ä»£ç å¤„ï¼Œå¹¶æŠŠ `masks` å¯è§†åŒ–å³å¯ã€‚  \n",
    ">\n",
    "> è¿™æ ·ï¼Œæœ¬ Notebook ä»ä¿æŒå•æ–‡ä»¶ç»“æ„ï¼Œä¾¿äº **â€œä¸€ä¸ªæ–‡ä»¶ä¸Š GitHubâ€** ä¸ **è¯¾å ‚ä¸€é”®æ¼”ç¤º**ã€‚\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
