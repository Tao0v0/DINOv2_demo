{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DINOv2 Attention Rollout Demo (qkv-hook, reg tokens fixed)\n",
        "\n",
        "一键运行：只需执行下方单个 Code Cell。包含：\n",
        "- 在线图片下载\n",
        "- timm 的 DINOv2 ViT-B/14 reg4 模型\n",
        "- 在 qkv 上 hook 并复原注意力\n",
        "- 最后 K 层 attention rollout + 叠加可视化\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://colab.research.google.com/"
        }
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ================== 一键依赖 ==================\n",
        "!pip -q install timm requests pillow matplotlib\n",
        "\n",
        "# ================== 导入 ==================\n",
        "import io, math, requests, torch, timm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "torch.set_grad_enabled(False)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ================== 在线图片（可改） ==================\n",
        "URLS = [\n",
        "    \"https://images.pexels.com/photos/1108099/pexels-photo-1108099.jpeg?auto=compress&cs=tinysrgb&w=1280\",\n",
        "    \"https://upload.wikimedia.org/wikipedia/commons/2/25/Universal_Robots_UR5.jpg\",\n",
        "    \"https://upload.wikimedia.org/wikipedia/commons/9/9f/KUKA_Industrial_Robot.jpg\",\n",
        "]\n",
        "def load_first_ok(urls):\n",
        "    hdr = {\"User-Agent\":\"Mozilla/5.0\"}\n",
        "    for u in urls:\n",
        "        try:\n",
        "            r = requests.get(u, headers=hdr, timeout=20); r.raise_for_status()\n",
        "            return Image.open(io.BytesIO(r.content)).convert(\"RGB\"), u\n",
        "        except Exception as e:\n",
        "            print(f\"[跳过] {u} -> {e}\")\n",
        "    raise RuntimeError(\"所有 URL 都不可用\")\n",
        "\n",
        "img_pil, used_url = load_first_ok(URLS)\n",
        "print(\"[OK] 使用图片：\", used_url)\n",
        "\n",
        "# ================== 模型（timm DINOv2 ViT-B/14 reg4） ==================\n",
        "model_id = 'vit_base_patch14_reg4_dinov2'\n",
        "model = timm.create_model(model_id, pretrained=True).to(device).eval()\n",
        "\n",
        "# 预处理（518×518 可被 14 整除 → 37×37 patch）\n",
        "IMG_SIZE = 518\n",
        "transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE), interpolation=T.InterpolationMode.BICUBIC),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "x = transform(img_pil).unsqueeze(0).to(device)\n",
        "\n",
        "# ================== Hook qkv 并前向 ==================\n",
        "qkv_per_block = []\n",
        "def qkv_hook(module, inp, out):\n",
        "    qkv_per_block.append(out.detach().cpu())\n",
        "\n",
        "handles = [blk.attn.qkv.register_forward_hook(qkv_hook) for blk in model.blocks]\n",
        "with torch.no_grad():\n",
        "    _ = model(x)\n",
        "for h in handles: h.remove()\n",
        "\n",
        "assert len(qkv_per_block) == len(model.blocks), \"没有捕获到 qkv，重跑单元试试\"\n",
        "\n",
        "# ================== 从 qkv 复原注意力 ==================\n",
        "num_heads = model.blocks[0].attn.num_heads\n",
        "embed_dim = model.blocks[0].attn.qkv.out_features // 3\n",
        "head_dim = embed_dim // num_heads\n",
        "scale = head_dim ** -0.5\n",
        "\n",
        "attn_per_block = []\n",
        "for qkv in qkv_per_block:\n",
        "    B, N, _ = qkv.shape\n",
        "    qkv = qkv.view(B, N, 3, num_heads, head_dim).permute(2, 0, 3, 1, 4)  # [3,B,H,N,Dh]\n",
        "    q, k = qkv[0], qkv[1]  # [B,H,N,Dh]\n",
        "    attn = torch.softmax((q @ k.transpose(-2, -1)) * scale, dim=-1)      # [B,H,N,N]\n",
        "    attn_per_block.append(attn.cpu())\n",
        "\n",
        "print(f\"[Info] 捕获到 {len(attn_per_block)} 层注意力；heads={num_heads}, tokens(N)={attn_per_block[0].shape[-1]}\")\n",
        "\n",
        "# ================== 计算 patch 网格和“额外 token”数量（reg tokens） ==================\n",
        "if hasattr(model.patch_embed, \"grid_size\"):\n",
        "    Hp, Wp = model.patch_embed.grid_size\n",
        "else:\n",
        "    # 兜底：按 N-1 近似平方根\n",
        "    N = attn_per_block[0].shape[-1]\n",
        "    Hp = Wp = int(round(math.sqrt(N-1)))\n",
        "patch_tokens = Hp * Wp\n",
        "\n",
        "N = attn_per_block[0].shape[-1]\n",
        "extra_tokens = N - (1 + patch_tokens)           # 例如 reg4 则为 4\n",
        "assert extra_tokens >= 0, \"token 数异常\"\n",
        "print(f\"[Info] Patch网格: {Hp}×{Wp}, 额外token数: {extra_tokens}\")\n",
        "\n",
        "# 一个帮助函数：取“CLS→patches”的向量（自动跳过 reg tokens）\n",
        "def cls_to_patches_vec(R):\n",
        "    # R: [B,N,N]，第0行为 CLS→所有token\n",
        "    start = 1 + extra_tokens                   # 跳过 CLS 和 reg tokens\n",
        "    end = start + patch_tokens\n",
        "    v = R[0, 0, start:end]                     # 长度应为 Hp*Wp\n",
        "    assert v.numel() == patch_tokens\n",
        "    return v\n",
        "\n",
        "# ================== Rollout ==================\n",
        "def attention_rollout(attn_list, last_k=None, head_fusion='mean', alpha=0.2):\n",
        "    if last_k is not None:\n",
        "        attn_list = attn_list[-last_k:]\n",
        "    B, H, N, _ = attn_list[0].shape\n",
        "    eye = torch.eye(N)[None].repeat(B,1,1)\n",
        "    R = eye.clone()\n",
        "    for A in attn_list:\n",
        "        A_f = A.mean(dim=1) if head_fusion=='mean' else A.max(dim=1).values\n",
        "        A_aug = (1 - alpha) * A_f + alpha * eye\n",
        "        A_aug = A_aug / (A_aug.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        R = A_aug @ R\n",
        "    return R  # [B,N,N]\n",
        "\n",
        "# ================== 可视化：逐层（使用最近 K 层聚焦） ==================\n",
        "K = 6\n",
        "fig, axes = plt.subplots(3, 4, figsize=(14,9))\n",
        "fig.suptitle(f'Attention Rollout per Block (CLS→patches) [{model_id}]', fontsize=14)\n",
        "\n",
        "for i in range(len(attn_per_block)):\n",
        "    R = attention_rollout(attn_per_block[:i+1], last_k=min(K, i+1), head_fusion='mean', alpha=0.2)\n",
        "    heat = cls_to_patches_vec(R).reshape(Hp, Wp).numpy()\n",
        "    ax = axes[i//4, i%4]\n",
        "    ax.imshow(heat, cmap='magma')\n",
        "    ax.set_title(f'Block: {i}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "# ================== 叠加回原图（最后 K 层） ==================\n",
        "R_last = attention_rollout(attn_per_block, last_k=K, head_fusion='mean', alpha=0.2)\n",
        "heat_last = cls_to_patches_vec(R_last).reshape(Hp, Wp).numpy()\n",
        "heat_last = (heat_last - heat_last.min()) / (heat_last.max() - heat_last.min() + 1e-6)\n",
        "\n",
        "H = W = IMG_SIZE\n",
        "from matplotlib import cm\n",
        "img_resize = img_pil.resize((W,H))\n",
        "heat_big = Image.fromarray((heat_last*255).astype(np.uint8)).resize((W,H), Image.BILINEAR)\n",
        "heat_rgb = (cm.viridis(np.array(heat_big)/255.0)[:,:,:3]*255).astype(np.uint8)\n",
        "overlay = Image.blend(img_resize, Image.fromarray(heat_rgb), alpha=0.45)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1); plt.title(\"Input\"); plt.imshow(img_resize); plt.axis('off')\n",
        "plt.subplot(1,2,2); plt.title(f\"Overlay (last {K} layers)\"); plt.imshow(overlay); plt.axis('off')\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}